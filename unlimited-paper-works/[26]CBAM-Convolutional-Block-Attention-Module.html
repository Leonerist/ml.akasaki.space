<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>CBAM: Convolutional Block Attention Module | 工具箱的深度学习记事簿</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/statics/logo.svg">
    <meta name="description" content="这里包含了我从入门到依然在入门的过程中接触到的大部分知识。翻翻目录，也许能找到有用的">
    <meta name="keywords" content="Akasaki,Deep learning,Machine learning,工具箱,工具箱的深度学习记事簿,Akasaki的深度学习记事簿">
    <meta name="google-site-verification" content="VVNYs0bXM_EKTgxJ8XIfvXShjHsksGNv3YNedxBGFjU">
    
    <link rel="preload" href="/assets/css/0.styles.b2187a0e.css" as="style"><link rel="preload" href="/assets/js/app.0cf0d483.js" as="script"><link rel="preload" href="/assets/js/2.d537feee.js" as="script"><link rel="preload" href="/assets/js/30.54f44e16.js" as="script"><link rel="prefetch" href="/assets/js/10.000b9996.js"><link rel="prefetch" href="/assets/js/100.01b72e43.js"><link rel="prefetch" href="/assets/js/101.ab99304f.js"><link rel="prefetch" href="/assets/js/102.b1ad1ca3.js"><link rel="prefetch" href="/assets/js/11.0ec32f4a.js"><link rel="prefetch" href="/assets/js/12.7ad41a4b.js"><link rel="prefetch" href="/assets/js/13.40c87056.js"><link rel="prefetch" href="/assets/js/14.2d8bcb8d.js"><link rel="prefetch" href="/assets/js/15.a7295b50.js"><link rel="prefetch" href="/assets/js/16.7158147a.js"><link rel="prefetch" href="/assets/js/17.9215c05c.js"><link rel="prefetch" href="/assets/js/18.582ac004.js"><link rel="prefetch" href="/assets/js/19.7cc8fc31.js"><link rel="prefetch" href="/assets/js/20.1b1e2af4.js"><link rel="prefetch" href="/assets/js/21.b2dadf61.js"><link rel="prefetch" href="/assets/js/22.b19748fc.js"><link rel="prefetch" href="/assets/js/23.f2db4fa1.js"><link rel="prefetch" href="/assets/js/24.3c31aece.js"><link rel="prefetch" href="/assets/js/25.531fd9fb.js"><link rel="prefetch" href="/assets/js/26.6e841782.js"><link rel="prefetch" href="/assets/js/27.33add335.js"><link rel="prefetch" href="/assets/js/28.35498a04.js"><link rel="prefetch" href="/assets/js/29.aabed81c.js"><link rel="prefetch" href="/assets/js/3.0a121536.js"><link rel="prefetch" href="/assets/js/31.8ecbe721.js"><link rel="prefetch" href="/assets/js/32.873f263a.js"><link rel="prefetch" href="/assets/js/33.106c15c8.js"><link rel="prefetch" href="/assets/js/34.349d6fdb.js"><link rel="prefetch" href="/assets/js/35.73569c69.js"><link rel="prefetch" href="/assets/js/36.24f08107.js"><link rel="prefetch" href="/assets/js/37.da460b69.js"><link rel="prefetch" href="/assets/js/38.2f6c4646.js"><link rel="prefetch" href="/assets/js/39.435f8032.js"><link rel="prefetch" href="/assets/js/4.972cd905.js"><link rel="prefetch" href="/assets/js/40.4760c47b.js"><link rel="prefetch" href="/assets/js/41.a7cc5e5d.js"><link rel="prefetch" href="/assets/js/42.fc3e47f2.js"><link rel="prefetch" href="/assets/js/43.a13c67d4.js"><link rel="prefetch" href="/assets/js/44.46c317cb.js"><link rel="prefetch" href="/assets/js/45.f11cdfc6.js"><link rel="prefetch" href="/assets/js/46.541bd27d.js"><link rel="prefetch" href="/assets/js/47.5705cba6.js"><link rel="prefetch" href="/assets/js/48.d2040c65.js"><link rel="prefetch" href="/assets/js/49.cbb5c42b.js"><link rel="prefetch" href="/assets/js/5.e2cb1c20.js"><link rel="prefetch" href="/assets/js/50.39732f79.js"><link rel="prefetch" href="/assets/js/51.99b82adb.js"><link rel="prefetch" href="/assets/js/52.808c9ece.js"><link rel="prefetch" href="/assets/js/53.67e417da.js"><link rel="prefetch" href="/assets/js/54.1c722ed6.js"><link rel="prefetch" href="/assets/js/55.afc1aceb.js"><link rel="prefetch" href="/assets/js/56.a463c15a.js"><link rel="prefetch" href="/assets/js/57.f90cb51c.js"><link rel="prefetch" href="/assets/js/58.8e11cf82.js"><link rel="prefetch" href="/assets/js/59.ed4fc789.js"><link rel="prefetch" href="/assets/js/6.59e5684c.js"><link rel="prefetch" href="/assets/js/60.adcefa1d.js"><link rel="prefetch" href="/assets/js/61.a6446644.js"><link rel="prefetch" href="/assets/js/62.1721a24b.js"><link rel="prefetch" href="/assets/js/63.726a6135.js"><link rel="prefetch" href="/assets/js/64.e2db755f.js"><link rel="prefetch" href="/assets/js/65.e92b9d46.js"><link rel="prefetch" href="/assets/js/66.b4d3e87e.js"><link rel="prefetch" href="/assets/js/67.5f3eaf29.js"><link rel="prefetch" href="/assets/js/68.85b4615c.js"><link rel="prefetch" href="/assets/js/69.63d409f1.js"><link rel="prefetch" href="/assets/js/7.b3ddb4c6.js"><link rel="prefetch" href="/assets/js/70.6f3f7332.js"><link rel="prefetch" href="/assets/js/71.0a087c8a.js"><link rel="prefetch" href="/assets/js/72.6513570f.js"><link rel="prefetch" href="/assets/js/73.896f4d9c.js"><link rel="prefetch" href="/assets/js/74.ecc3d286.js"><link rel="prefetch" href="/assets/js/75.b06a8964.js"><link rel="prefetch" href="/assets/js/76.3032add1.js"><link rel="prefetch" href="/assets/js/77.4fb4de51.js"><link rel="prefetch" href="/assets/js/78.42cf5412.js"><link rel="prefetch" href="/assets/js/79.0ba88830.js"><link rel="prefetch" href="/assets/js/8.bb97c23d.js"><link rel="prefetch" href="/assets/js/80.aaa6656c.js"><link rel="prefetch" href="/assets/js/81.4a1804f1.js"><link rel="prefetch" href="/assets/js/82.7ad53f0e.js"><link rel="prefetch" href="/assets/js/83.c4173111.js"><link rel="prefetch" href="/assets/js/84.cb7300ea.js"><link rel="prefetch" href="/assets/js/85.81c0ea84.js"><link rel="prefetch" href="/assets/js/86.317fcc1c.js"><link rel="prefetch" href="/assets/js/87.6f50a42f.js"><link rel="prefetch" href="/assets/js/88.898a4cd8.js"><link rel="prefetch" href="/assets/js/89.ddbe5c5c.js"><link rel="prefetch" href="/assets/js/9.596e7f45.js"><link rel="prefetch" href="/assets/js/90.c1e40160.js"><link rel="prefetch" href="/assets/js/91.f85fdec8.js"><link rel="prefetch" href="/assets/js/92.1d7822a2.js"><link rel="prefetch" href="/assets/js/93.4ee2ef21.js"><link rel="prefetch" href="/assets/js/94.3760a5b4.js"><link rel="prefetch" href="/assets/js/95.b5be500a.js"><link rel="prefetch" href="/assets/js/96.e570f48e.js"><link rel="prefetch" href="/assets/js/97.af175cfb.js"><link rel="prefetch" href="/assets/js/98.ca3ecf81.js"><link rel="prefetch" href="/assets/js/99.2fc27711.js">
    <link rel="stylesheet" href="/assets/css/0.styles.b2187a0e.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">工具箱的深度学习记事簿</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="https://github.com/VisualDust/ml.akasaki.space" target="_blank" rel="noopener noreferrer" class="nav-link external">
  View on Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://github.com/VisualDust" target="_blank" rel="noopener noreferrer" class="nav-link external">
  工具箱
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="https://github.com/VisualDust/ml.akasaki.space" target="_blank" rel="noopener noreferrer" class="nav-link external">
  View on Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://github.com/VisualDust" target="_blank" rel="noopener noreferrer" class="nav-link external">
  工具箱
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第零章：在开始之前</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第一章上：HelloWorld</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第一章下：深度学习基础</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第二章上：卷积神经网络</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第二章下：经典卷积神经网络</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第三章上：谈一些计算机视觉方向</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第三章下：了解更高级的技术</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>魔法部日志（又名论文阅读日志）</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/unlimited-paper-works/[0]unlimited-paper-works.html" class="sidebar-link">欢迎来到魔法部日志</a></li><li><a href="/unlimited-paper-works/[1]The-Devil-is-in-the-Decoder-Classification-Regression-and-GANs.html" class="sidebar-link">The Devil is in the Decoder: Classification, Regression and GANs</a></li><li><a href="/unlimited-paper-works/[2]Threat-of-Adversarial-Attacks-on-Deep-Learning-in-Computer-Vision-A-Survey.html" class="sidebar-link">Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey</a></li><li><a href="/unlimited-paper-works/[3]Progressive-Semantic-Segmentation.html" class="sidebar-link">Progressive Semantic Segmentation</a></li><li><a href="/unlimited-paper-works/[4]Decoders-Matter-for-Semantic-Segmentation-Data-Dependent-Decoding-Enables-Flexible-Feature-Aggregation.html" class="sidebar-link">Decoders Matter for Semantic Segmentation: Data-Dependent Decoding Enables Flexible Feature Aggregation</a></li><li><a href="/unlimited-paper-works/[5]HLA-Face-Joint-High-Low-Adaptation-for-Low-Light-Face-Detection.html" class="sidebar-link">HLA-Face Joint High-Low Adaptation for Low Light Face Detection</a></li><li><a href="/unlimited-paper-works/[6]DeepLab-Series.html" class="sidebar-link">DeepLab Series</a></li><li><a href="/unlimited-paper-works/[7]Cross-Dataset-Collaborative-Learning-for-Semantic-Segmentation.html" class="sidebar-link">Cross-Dataset Collaborative Learning for Semantic Segmentation</a></li><li><a href="/unlimited-paper-works/[8]Dynamic-Neural-Networks-A-Survey.html" class="sidebar-link">Dynamic Neural Networks: A Survey</a></li><li><a href="/unlimited-paper-works/[9]Feature-Pyramid-Networks-for-Object-Detection.html" class="sidebar-link">Feature Pyramid Networks for Object Detection</a></li><li><a href="/unlimited-paper-works/[10]Overview-Of-Semantic-Segmentation.html" class="sidebar-link">A Review on Deep Learning Techniques Applied to Semantic Segmentation</a></li><li><a href="/unlimited-paper-works/[11]Image-Segmentation-Using-Deep-Learning-A-Survey.html" class="sidebar-link">Image Segmentation Using Deep Learning: A Survey</a></li><li><a href="/unlimited-paper-works/[12]MobileNetV2-Inverted-Residuals-and-Linear-bottleneck.html" class="sidebar-link">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></li><li><a href="/unlimited-paper-works/[13]Fast-SCNN-Fast-Semantic-Segmentation-Network.html" class="sidebar-link">Fast-SCNN: Fast Semantic Segmentation Network</a></li><li><a href="/unlimited-paper-works/[14]MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Applications.html" class="sidebar-link">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a></li><li><a href="/unlimited-paper-works/[15]Gated-Channel-Transformation-for-Visual-Recognition.html" class="sidebar-link">Gated Channel Transformation for Visual Recognition</a></li><li><a href="/unlimited-paper-works/[16]Convolutional-Block-Attention-Module.html" class="sidebar-link">Convolutional Block Attention Module</a></li><li><a href="/unlimited-paper-works/[17]Boundary-IoU-Improving-Object-Centri Image-Segmentation-Evaluation.html" class="sidebar-link">Boundary IoU: Improving Object-Centric Image Segmentation Evaluation</a></li><li><a href="/unlimited-paper-works/[18]Involution-Inverting-the-Inherence-of-Convolution-for-Visual-Recognition.html" class="sidebar-link">Involution: Inverting the Inherence of Convolution for Visual Recognition</a></li><li><a href="/unlimited-paper-works/[19]PointRend-Image-Segmentation-as-Rendering.html" class="sidebar-link">PointRend: Image Segmentation as Rendering</a></li><li><a href="/unlimited-paper-works/[20]Transformer-Attention-is-all-you-need.html" class="sidebar-link">Transformer: Attention is all you need</a></li><li><a href="/unlimited-paper-works/[21]RefineMask_Towards_High-Quality_Instance_Segmentationwith_Fine-Grained_Features.html" class="sidebar-link">RefineMask: Towards High-Quality Instance Segmentationwith Fine-Grained Features</a></li><li><a href="/unlimited-paper-works/[22]GLADNet-Low-Light-Enhancement-Network-with-Global-Awareness.html" class="sidebar-link">GLADNet: Low-Light Enhancement Network with Global Awareness</a></li><li><a href="/unlimited-paper-works/[23]Squeeze-and-Excitation-Networks.html" class="sidebar-link">Squeeze-and-Excitation Networks (SENet)</a></li><li><a href="/unlimited-paper-works/[24]BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation.html" class="sidebar-link">BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation</a></li><li><a href="/unlimited-paper-works/[25]Rethinking-BiSeNet-For-Real-time-Semantic-Segmentation.html" class="sidebar-link">Rethinking BiSeNet For Real-time Semantic Segmentation</a></li><li><a href="/unlimited-paper-works/[26]CBAM-Convolutional-Block-Attention-Module.html" class="active sidebar-link">CBAM: Convolutional Block Attention Module</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/unlimited-paper-works/[26]CBAM-Convolutional-Block-Attention-Module.html#channel-attention-module-通道注意力" class="sidebar-link">Channel Attention Module（通道注意力）</a></li><li class="sidebar-sub-header"><a href="/unlimited-paper-works/[26]CBAM-Convolutional-Block-Attention-Module.html#spatial-attention-module-空间注意力" class="sidebar-link">Spatial Attention Module（空间注意力）</a></li><li class="sidebar-sub-header"><a href="/unlimited-paper-works/[26]CBAM-Convolutional-Block-Attention-Module.html#convolutional-block-attention-module" class="sidebar-link">Convolutional Block Attention Module</a></li><li class="sidebar-sub-header"><a href="/unlimited-paper-works/[26]CBAM-Convolutional-Block-Attention-Module.html#example" class="sidebar-link">Example</a></li></ul></li><li><a href="/unlimited-paper-works/[27]Non-local-Neural-Networks.html" class="sidebar-link">Non-local Neural Networks</a></li><li><a href="/unlimited-paper-works/[28]GCNet-Non-local-Networks-Meet-Squeeze-Excitation-Networks-and-Beyond.html" class="sidebar-link">GCNet: Global Context Networks (Non-local Networks Meet Squeeze-Excitation Networks and Beyond)</a></li><li><a href="/unlimited-paper-works/[29]Disentangled-Non-Local-Neural-Networks.html" class="sidebar-link">Disentangled Non-Local Neural Networks</a></li><li><a href="/unlimited-paper-works/[30]RetinexNet-for-Low-Light-Enhancement.html" class="sidebar-link">Deep Retinex Decomposition for Low-Light Enhancement</a></li><li><a href="/unlimited-paper-works/[31]MSR-netLow-light-Image-Enhancement-Using-Deep-Convolutional-Network.html" class="sidebar-link">MSR-net:Low-light Image Enhancement Using Deep Convolutional Network</a></li><li><a href="/unlimited-paper-works/[32]LLCNN-A-Convolutional-Neural-Network-for-Low-light-Image-Enhancement.html" class="sidebar-link">LLCNN: A convolutional neural network for low-light image enhancement</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>附录1：好朋友们</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>附录2：数学是真正的圣经</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>附录3：信号和采样的学问（DSP）</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>附录4：TensorFlow编程策略</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="cbam-convolutional-block-attention-module"><a href="#cbam-convolutional-block-attention-module" class="header-anchor">#</a> CBAM: Convolutional Block Attention Module</h1> <p><img src="/assets/img/image-20210723203210974.2f7af0ab.png" alt="image-20210723203210974"></p> <p><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Woo%2C+S" target="_blank" rel="noopener noreferrer">Sanghyun Woo<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+J" target="_blank" rel="noopener noreferrer">Jongchan Park<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+J" target="_blank" rel="noopener noreferrer">Joon-Young Lee<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kweon%2C+I+S" target="_blank" rel="noopener noreferrer">In So Kweon<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <blockquote><p>We propose Convolutional Block Attention Module (CBAM), a simple yet effective attention module for feed-forward convolutional neural networks. Given an intermediate feature map, our module sequentially infers attention maps along two separate dimensions, channel and spatial, then the attention maps are multiplied to the input feature map for adaptive feature refinement. Because CBAM is a lightweight and general module, it can be integrated into any CNN architectures seamlessly with negligible overheads and is end-to-end trainable along with base CNNs. We validate our CBAM through extensive experiments on ImageNet-1K, MS~COCO detection, and VOC~2007 detection datasets. Our experiments show consistent improvements in classification and detection performances with various models, demonstrating the wide applicability of CBAM. The code and models will be publicly available.</p></blockquote> <p>CBAM是一篇结合了通道注意力和空间注意力的论文。它通过在同个模块中叠加通道注意力和空间注意力达到了良好的效果。为了提升 CNN 模型的表现，除了对网络的深度、宽度下手，还有一个方向是注意力。注意力不仅要告诉我们重点关注哪里，提高关注点的表达。 我们的目标是通过使用注意机制来增加表现力，关注重要特征并抑制不必要的特征。</p> <p>为了强调空间和通道这两个维度上的有意义特征，作者依次应用通道和空间注意模块，来分别优化卷积神经网络在通道和空间维度上学习能力。作者将注意力过程分为通道和空间两个独立的部分，这样做不仅可以节约参数和计算力，而且保证了其可以作为即插即用的模块集成到现有的网络架构中去。</p> <hr> <h2 id="channel-attention-module-通道注意力"><a href="#channel-attention-module-通道注意力" class="header-anchor">#</a> Channel Attention Module（通道注意力）</h2> <p>关于通道注意力的相关设计细节请参考<a href="/unlimited-paper-works/[23]Squeeze-and-Excitation-Networks.html">Squeeze-and-Excitation Networks (SENet)</a>。在这里不进行非常详细的设计。特征的每一个通道都代表着一个专门的检测器，因此，通道注意力是关注什么样的特征是有意义的。为了汇总空间特征，作者采用了全局平均池化和最大池化两种方式来分别利用不同的信息。</p> <p><img src="/assets/img/image-20210723194442312.cff33f2a.png" alt="image-20210723194442312"></p> <p>在这篇论文中，作者使用Global Average Pool和Max Pool共用构造Channel wise的注意力。如上图所示，输入是一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>×</mo><mi>W</mi><mo>×</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">H\times W\times C</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span>的特征 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi></mrow><annotation encoding="application/x-tex">F</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span></span></span></span>，我们先分别进行一个空间的全局平均池化和最大池化得到两个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>1</mn><mo>×</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">1\times 1\times C</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span>的通道描述。接着，再将它们分别送入一个两层的神经网络，第一层神经元个数为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mi mathvariant="normal">/</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">C/r</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span>，激活函数为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>e</mi><mi>L</mi><mi>U</mi></mrow><annotation encoding="application/x-tex">ReLU</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10903em;">LU</span></span></span></span>，第二层神经元个数为。注意，它们使用共享的参数建立通道相关性。将得到的通道描述乘以输入特征<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi></mrow><annotation encoding="application/x-tex">F</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span></span></span></span>即可得到加入了通道相关性的特征。</p> <p>相较于原本的<a href="/unlimited-paper-works/[23]Squeeze-and-Excitation-Networks.html">SENet</a>，本文同时使用Global Average Pooling和Max Pooling。在后续的实验结果中可以看到，在通道注意力模块中，同时引入最大池化和平均池化可以得到最好的效果。</p> <h2 id="spatial-attention-module-空间注意力"><a href="#spatial-attention-module-空间注意力" class="header-anchor">#</a> Spatial Attention Module（空间注意力）</h2> <p><img src="/assets/img/image-20210723194510586.9517658d.png" alt="image-20210723194510586"></p> <p>与通道注意力相似，给定一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>×</mo><mi>W</mi><mo>×</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">H\times W\times C</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> 的特征 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi></mrow><annotation encoding="application/x-tex">F</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span></span></span></span>，先分别进行一个通道维度的平均池化和最大池化得到两个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>×</mo><mi>W</mi><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">H\times W\times 1</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> 的通道描述，并将这两个描述按照通道拼接在一起。经过一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn><mo>×</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">7\times 7</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">7</span></span></span></span> 的卷积层，激活函数为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>o</mi><mi>i</mi><mi>d</mi></mrow><annotation encoding="application/x-tex">Sigmoid</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span></span></span></span>，得到权重系数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>M</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">M_s</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。将权重系数和特征 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi></mrow><annotation encoding="application/x-tex">F</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span></span></span></span> 相乘即可得到加入了空间注意力的特征图。</p> <p>在空间注意力模块中，同时引入最大池化和平均池化比利用一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1\times 1</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> 的卷积要好，同时，卷积层采用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn><mo>×</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">7\times 7</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">7</span></span></span></span> 的卷积核要优于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3\times 3</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span> 的卷积核。</p> <h2 id="convolutional-block-attention-module"><a href="#convolutional-block-attention-module" class="header-anchor">#</a> Convolutional Block Attention Module</h2> <p>通道注意力和空间注意力这两个模块可以以并行或者顺序的方式组合在一起，但是作者发现顺序组合并且将通道注意力放在前面可以取得更好的效果。</p> <p><img src="/assets/img/image-20210723194528528.0a45f813.png" alt="image-20210723194528528"></p> <p>一个完整的 CBAM 模块如上图所示，其 TensorFlow 的一个实现如下所示：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">CBAM</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> reduction<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    @Convolutional Block Attention Module
    &quot;&quot;&quot;</span>

    _<span class="token punctuation">,</span> width<span class="token punctuation">,</span> height<span class="token punctuation">,</span> channel <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">.</span>get_shape<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># (B, W, H, C)</span>

    <span class="token comment"># channel attention</span>
    x_mean <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>   <span class="token comment"># (B, 1, 1, C)</span>
    x_mean <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>x_mean<span class="token punctuation">,</span> channel <span class="token operator">//</span> reduction<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'CA1'</span><span class="token punctuation">)</span>  <span class="token comment"># (B, 1, 1, C // r)</span>
    x_mean <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>x_mean<span class="token punctuation">,</span> channel<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'CA2'</span><span class="token punctuation">)</span>   <span class="token comment"># (B, 1, 1, C)</span>

    x_max <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_max<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># (B, 1, 1, C)</span>
    x_max <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>x_max<span class="token punctuation">,</span> channel <span class="token operator">//</span> reduction<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'CA1'</span><span class="token punctuation">,</span> reuse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token comment"># (B, 1, 1, C // r)</span>
    x_max <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>x_max<span class="token punctuation">,</span> channel<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'CA2'</span><span class="token punctuation">,</span> reuse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># (B, 1, 1, C)</span>

    x <span class="token operator">=</span> tf<span class="token punctuation">.</span>add<span class="token punctuation">(</span>x_mean<span class="token punctuation">,</span> x_max<span class="token punctuation">)</span>   <span class="token comment"># (B, 1, 1, C)</span>
    x <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment"># (B, 1, 1, C)</span>
    x <span class="token operator">=</span> tf<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>   <span class="token comment"># (B, W, H, C)</span>

    <span class="token comment"># spatial attention</span>
    y_mean <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># (B, W, H, 1)</span>
    y_max <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_max<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># (B, W, H, 1)</span>
    y <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>y_mean<span class="token punctuation">,</span> y_max<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>     <span class="token comment"># (B, W, H, 2)</span>
    y <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>y<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>sigmoid<span class="token punctuation">)</span>    <span class="token comment"># (B, W, H, 1)</span>
    y <span class="token operator">=</span> tf<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  <span class="token comment"># (B, W, H, C)</span>

    <span class="token keyword">return</span> y
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br></div></div><h2 id="example"><a href="#example" class="header-anchor">#</a> Example</h2> <p>使用该模块的例子，如将其集成于ResNet中：</p> <p><img src="/assets/img/image-20210723203033736.2daf8ad8.png" alt="image-20210723203033736"></p></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">上次更新时间:</span> <span class="time">2021/7/27 上午4:27:40</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/unlimited-paper-works/[25]Rethinking-BiSeNet-For-Real-time-Semantic-Segmentation.html" class="prev">
        Rethinking BiSeNet For Real-time Semantic Segmentation
      </a></span> <span class="next"><a href="/unlimited-paper-works/[27]Non-local-Neural-Networks.html">
        Non-local Neural Networks
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.0cf0d483.js" defer></script><script src="/assets/js/2.d537feee.js" defer></script><script src="/assets/js/30.54f44e16.js" defer></script>
  </body>
</html>
